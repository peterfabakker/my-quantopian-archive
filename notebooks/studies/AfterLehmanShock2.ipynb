{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary Pipeline modules\n",
    "from quantopian.pipeline import Pipeline, CustomFactor\n",
    "from quantopian.research import run_pipeline\n",
    "from quantopian.pipeline.filters.morningstar import Q500US\n",
    "from quantopian.pipeline.factors import AverageDollarVolume, Latest,Returns\n",
    "from quantopian.pipeline.factors.morningstar import MarketCap\n",
    "from quantopian.pipeline.data.builtin import USEquityPricing\n",
    "from quantopian.pipeline.classifiers.morningstar import Sector\n",
    "from quantopian.pipeline.data import morningstar\n",
    "from quantopian.interactive.data.eventvestor import dividends_free  as dataset\n",
    "#\n",
    "from zipline.utils.tradingcalendar import trading_day  \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from odo import odo\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "sector_mappings = {  \n",
    "   101.0: \"Basic Materials\",  \n",
    "   102.0: \"Consumer Cyclical\",  \n",
    "   103.0: \"Financial Services\",  \n",
    "   104.0: \"Real Estate\",  \n",
    "   205.0: \"Consumer Defensive\",  \n",
    "   206.0: \"Healthcare\",  \n",
    "   207.0: \"Utilites\",  \n",
    "   308.0: \"Communication Services\",  \n",
    "   309.0: \"Energy\",  \n",
    "   310.0: \"Industrials\",  \n",
    "   311.0: \"Technology\"  \n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leamanショック頃\n",
    "start = \"2010-05-07\"#\"2008-9-29\"\n",
    "end = \"2010-08-07\"#\"2009-3-10\"\n",
    "#end = \"2008-12-10\"\n",
    "period = 30\n",
    "spy = get_pricing(\"spy\", start_date=start, end_date=end, fields='price', frequency='daily')\n",
    "research_start_date = spy.pct_change().sort_values().index[0].date()\n",
    "print \"SPYが一番下がった日： \", research_start_date\n",
    "research_end_date = pd.date_range(research_start_date, periods=period, freq=trading_day)[-1].date()\n",
    "print \"調査期間：%s ~ %s\" % (research_start_date, research_end_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DividendYield(CustomFactor):  \n",
    "    \"\"\"  \n",
    "    Computes (or rather fetches) dividend yield\n",
    "    \"\"\"  \n",
    "    inputs = [morningstar.valuation_ratios.dividend_yield]\n",
    "    window_length = 1\n",
    "    \n",
    "    def compute(self, today, assets, out, dividend_yield):  \n",
    "        out[:] = dividend_yield \n",
    "        \n",
    "pipe = Pipeline()\n",
    "pipe.add(Returns(window_length=2), \"Returns\")\n",
    "pipe.add(USEquityPricing.close.latest, \"Latest\")\n",
    "pipe.add(MarketCap(), \"MarketCap\")\n",
    "pipe.add(Sector(), \"Sector\")\n",
    "pipe.add(morningstar.valuation_ratios.pe_ratio.latest , \"PER\")\n",
    "pipe.add(morningstar.valuation_ratios.book_value_yield.latest, \"PBR\") # 本当にPBRかどうか怪しいので確認\n",
    "pipe.add(DividendYield(), 'DividendYield')\n",
    "\n",
    "pipe.set_screen(Q500US())        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = run_pipeline(pipe, research_start_date, research_end_date)\n",
    "returns = result.Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_list = [\"2008-01-17\",\"2008-07-02\", \"2008-09-09\", \"2010-05-20\", \"2011-08-04\", \"2011-11-21\", \"2015-08-24\", \"2015-09-28\", \"2016-01-13\"]\n",
    "period = 30\n",
    "research_dates = []\n",
    "\n",
    "for start in start_date_list:\n",
    "    research_start_date = pd.to_datetime(start).date()\n",
    "    research_end_date = pd.date_range(research_start_date, periods=period, freq=trading_day)[-1].date()\n",
    "    \n",
    "    research_dates.append((research_start_date,research_end_date))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for start, end in research_dates:\n",
    "    print start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list()\n",
    "for start, end in research_dates:\n",
    "    print (start, end)\n",
    "    result = run_pipeline(pipe, start, end)\n",
    "    #returns = result.Returns\n",
    "    l.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l[0][\"PBR\"].reset_index().mean()\n",
    "l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for returns in l:\n",
    "    log_returns = returns.apply(lambda x: np.log(x+1))\n",
    "    log_change_by_asset = log_returns.reset_index().groupby(['level_1']).sum().sort_values(by='Returns', ascending=False)\n",
    "    change_by_asset = log_change_by_asset.apply(lambda x: np.exp(x)-1)\n",
    "    change_by_asset.ix[:10].plot(kind='bar', legend=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = pd.concat(l)\n",
    "log_returns = returns.apply(lambda x: np.log(x+1))\n",
    "log_change_by_asset = log_returns.reset_index().groupby(['level_1']).sum().sort_values(by='Returns', ascending=False)\n",
    "change_by_asset = log_change_by_asset.apply(lambda x: np.exp(x)-1)\n",
    "change_by_asset.plot(kind='bar', legend=False)\n",
    "print \"調査期間でのSP500っぽい銘柄の銘柄別累積変化率\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"調査期間内で変化率がポジティブにだったSP500銘柄数\", \n",
    "len(change_by_asset[change_by_asset.Returns > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_by_sector = result[['Returns', 'Sector', 'MarketCap']]\n",
    "return_by_sector.loc[:, 'LogReturn'] = return_by_sector.Returns.apply(lambda x: np.log(x+1))\n",
    "return_by_sector.loc[:, 'CapChange'] = return_by_sector.Returns * return_by_sector.MarketCap\n",
    "sum_returns_by_sector = return_by_sector.reset_index().groupby(['level_1']).mean().groupby(['Sector']).mean().rename(index= sector_mappings)\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(1,2,1)\n",
    "bx = fig.add_subplot(1,2,2)\n",
    "sum_returns_by_sector.sort_values(by='LogReturn', ascending=False)['LogReturn'].plot(kind='bar', ax=ax)\n",
    "sum_returns_by_sector.sort_values(by='CapChange', ascending=False)['CapChange'].plot(kind='bar', ax=bx)\n",
    "plt.title(\"by setcor\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_by_sector[return_by_sector.Sector==207].reset_index().groupby(\"level_1\").sum().sort_values(by=\"Returns\")['Returns'].plot(kind='bar')\n",
    "plt.title(\"Utilites setcors\")\n",
    "\n",
    "# for sid in returns_by_sector[returns_by_sector.Sector==207].reset_index().groupby(\"level_1\").sum().index:\n",
    "#     print sid, sid.security_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = result[['Returns', 'DividendYield', 'PER', 'PBR', 'MarketCap', 'Sector']]\n",
    "r.loc[:, 'lnReturns'] = result.Returns.apply(lambda x: np.log(x+1))\n",
    "r.loc[:, 'lnDividendYield'] = result.DividendYield.apply(lambda x: np.log(x+1))\n",
    "r.loc[:, 'lnPER'] = result.PER.apply(lambda x: np.log(x+1))\n",
    "r.loc[:, 'lnPBR'] = result.PBR.apply(lambda x: np.log(x+1))\n",
    "r.loc[:, 'lnMarketCap'] = result.MarketCap.apply(lambda x: np.log(x+1))\n",
    "r.loc[:, 'Robust'] = [int(v) in [207, 206, 308, 309] for v in result.Sector]\n",
    "r.loc[:, 'Fragile'] = [int(v) in [103, 104, 311] for v in result.Sector]\n",
    "r = r.reset_index().groupby(['level_1']).mean()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.2, hspace=0.4)\n",
    "for i, c in enumerate(['lnDividendYield','lnPER', 'lnPBR', 'lnMarketCap']):\n",
    "    ax = fig.add_subplot(1,4,i+1)\n",
    "    ax.scatter(r[c], r.lnReturns, alpha=0.2)\n",
    "    ax.set_title(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regr = RandomForestRegressor(max_depth=5, random_state=0)\n",
    "df = r.copy().dropna()\n",
    "df = df.iloc[np.random.permutation(len(df))]\n",
    "X = df[['lnDividendYield', 'lnPER', 'lnPBR', 'lnMarketCap', 'Robust', 'Fragile']]\n",
    "y = df['lnReturns']\n",
    "n = int(len(X)*0.6)\n",
    "X_train = X[:n]\n",
    "y_train = y[:n]\n",
    "X_test = X[n:]\n",
    "y_test = y[n:]\n",
    "regr.fit(X_train, y_train)\n",
    "plt.scatter(regr.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.concat([X_test, \n",
    "                  pd.DataFrame(regr.predict(X_test), columns=['pred'], index=X_test.index), #\n",
    "                  pd.DataFrame([[v] for v in y_test], columns=['actual'],index=X_test.index )], axis=1) #\n",
    "df_test = df_test.sort_values(by='pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "for e in df_test.head(n).index:\n",
    "    ps = result.xs([e], level=[1])['Latest']\n",
    "    ps = ps/ps[0]\n",
    "    ps.plot(color='red', alpha=0.5)\n",
    "for e in df_test.tail(n).index:\n",
    "    ps = result.xs([e], level=[1])['Latest']\n",
    "    ps = ps/ps[0]\n",
    "    ps.plot(color='blue', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantopian.interactive.data.quandl import cboe_vix\n",
    "from odo import odo\n",
    "df = odo(cboe_vix, pd.DataFrame)\n",
    "df['asof_date'] = pd.to_datetime(df['asof_date'])\n",
    "df = df.set_index(['asof_date'])\n",
    "df = df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.vix_close > 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "start=df.index[0]\n",
    "end = df.index[-1]\n",
    "spy = get_pricing('spy', start_date=start, end_date=end, frequency='daily', fields=['price', 'high'])\n",
    "spy['MA10'] =talib.MA(spy.price, timeperiod=10)\n",
    "spy['MA30'] = talib.MA(spy.price, timeperiod=30)\n",
    "spy['diff_30'] = spy.price / spy.MA30 - 1 \n",
    "spy['VIX'] = df.vix_close.values\n",
    "spy['RollingMax90'] = pd.rolling_max(spy.high, 90)\n",
    "spy['diff_rm90'] = spy.price / spy.RollingMax90 - 1 \n",
    "spy['target'] = (spy.VIX > 25) & (spy.diff_rm90 < -0.10) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spy.plot(x = 'diff_rm90', y = 'VIX', kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = spy[spy.target].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates[42] + pd.DateOffset(30) <dates[43]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date=pd.to_datetime(start) + pd.DateOffset(period), \n",
    "\n",
    "for i, date in enumerate(dates[1:]):\n",
    "    if dates[i-1] + pd.DateOffset(30) < date  :\n",
    "        print date\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shift(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
