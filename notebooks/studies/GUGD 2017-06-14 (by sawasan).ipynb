{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantopian.pipeline.data.builtin import USEquityPricing\n",
    "from quantopian.pipeline.factors import SimpleMovingAverage,RSI\n",
    "from quantopian.research import run_pipeline\n",
    "from quantopian.pipeline import Pipeline,CustomFilter\n",
    "from quantopian.pipeline.factors import CustomFactor,RSI\n",
    "from quantopian.pipeline.data import morningstar\n",
    "from zipline import TradingAlgorithm  \n",
    "from quantopian.pipeline.filters import Q1500US, Q500US\n",
    "from quantopian.pipeline.factors import AverageDollarVolume\n",
    "from quantopian.pipeline.classifiers.morningstar import Sector, SuperSector\n",
    "#\n",
    "#from quantopian.pipeline.data.alpha_vertex import precog_top_500 as precog\n",
    "#\n",
    "import numpy as np\n",
    "import talib \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.cm as cm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###過去データを作成\n",
    "\n",
    "```python\n",
    "start_date='2017-5-15'\n",
    "end_date='2017-6-1'\n",
    "pipeline_results = build_pipeline(start_date, end_date)\n",
    "```\n",
    "\n",
    "を実行して得られるpipeline_resultsは，日付とsid（銘柄id）の2つをマルチインデックスとして持つDataFrame.\n",
    "\n",
    "make_pipelineの中で指定されている ```columns=``` をコラムとして持つ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PrevClose(CustomFactor):\n",
    "    inputs = [USEquityPricing.close]\n",
    "    window_length = 2\n",
    "    def compute(self, today, assets, out, close):\n",
    "        out[:] = close[-1]\n",
    "\n",
    "class PrevVolume(CustomFactor):\n",
    "    inputs = [USEquityPricing.volume]\n",
    "    window_length = 2\n",
    "    def compute(self, today, assets, out, close):\n",
    "        out[:] = close[-1]\n",
    "\n",
    "class FinancialFactor(CustomFactor):\n",
    "    window_length = 2\n",
    "    def compute(self, today, assets, out, v): \n",
    "        out[:] = v[0]\n",
    "        \n",
    "class MarketCap(FinancialFactor):\n",
    "    inputs = [morningstar.valuation.market_cap]\n",
    "    def compute(self, today, assets, out, v): \n",
    "        out[:] = np.log(v[0])\n",
    "    \n",
    "class ROA(FinancialFactor):\n",
    "    inputs = [morningstar.operation_ratios.roa]\n",
    "     \n",
    "class ROE(FinancialFactor):\n",
    "    inputs = [morningstar.operation_ratios.roe]\n",
    "\n",
    "class NormalizedBasicEps(FinancialFactor):\n",
    "    inputs = [morningstar.earnings_report.normalized_basic_eps]\n",
    "\n",
    "class NetIncomeGrowth(FinancialFactor):\n",
    "    inputs = [morningstar.operation_ratios.net_income_growth]\n",
    "\n",
    "class PE(FinancialFactor):\n",
    "    inputs = [morningstar.valuation_ratios.pe_ratio]\n",
    "\n",
    "class BookValueYield(FinancialFactor):\n",
    "    inputs = [morningstar.valuation_ratios.book_value_yield]\n",
    "\n",
    "class DividendYield(FinancialFactor):\n",
    "    inputs = [morningstar.valuation_ratios.dividend_yield]\n",
    "\n",
    "# class ShortName(FinancialFactor):\n",
    "#     inputs = [morningstar.company_reference.short_name]\n",
    "#     def compute(self, today, assets, out, v): \n",
    "#         out[:] = np.array(v[0])\n",
    "\n",
    "class PeriodEndingDate(FinancialFactor):\n",
    "    inputs = [morningstar.financial_statement_filing.period_ending_date]\n",
    "    \n",
    "    \n",
    "def make_pipeline(high_dollar_volume_thresh_min, high_dollar_volume_thresh_max):\n",
    "    #\n",
    "    base_universe = Q500US() \n",
    "    #\n",
    "    yesterday_close = PrevClose()\n",
    "    yesterday_volume = PrevVolume()\n",
    "    dollar_volume = AverageDollarVolume(window_length=30)\n",
    "    #ToDo この範囲を色々変えてみる．\n",
    "    high_dollar_volume = dollar_volume.percentile_between(high_dollar_volume_thresh_min, high_dollar_volume_thresh_max)\n",
    "    sector = Sector()\n",
    "    rsi = RSI(inputs=[USEquityPricing.close])\n",
    "\n",
    "    columns = {\n",
    "        'yesterday_close': yesterday_close,\n",
    "        'yesterday_volume': yesterday_volume,\n",
    "        'yesterday_turnover': yesterday_close * yesterday_volume,\n",
    "        'dollar_volume': dollar_volume,\n",
    "        'high_dollar_volume': high_dollar_volume,\n",
    "        'sector': sector,\n",
    "        'rsi': rsi,\n",
    "        'market_cap': MarketCap(),\n",
    "        'roa': ROA(),\n",
    "        'roe': ROE(),\n",
    "        'normalized_basic_eps': NormalizedBasicEps(),\n",
    "        'net_income_growth': NetIncomeGrowth(),\n",
    "        'pe': PE(),\n",
    "        'book_value_yield': BookValueYield(),\n",
    "        'dividend_yield': DividendYield(),\n",
    "        #'short_name': ShortName(),\n",
    "        'period_ending_date': PeriodEndingDate(),\n",
    "    }\n",
    "    screen = base_universe & high_dollar_volume\n",
    "    #\n",
    "    pipe = Pipeline(\n",
    "        columns = columns,\n",
    "        screen = screen\n",
    "    )\n",
    "    return pipe\n",
    "\n",
    "def build_pipeline(start_date, end_date, high_dollar_volume_thresh_min, high_dollar_volume_thresh_max):\n",
    "    pipeline_results = run_pipeline(make_pipeline(high_dollar_volume_thresh_min, high_dollar_volume_thresh_max), \n",
    "                                    start_date=start_date, end_date=end_date)\n",
    "    return pipeline_results\n",
    "\n",
    "    \n",
    "def add_exdates(pipeline_results, df_exdate):\n",
    "    \"\"\"\n",
    "    df_exdate = local_csv(\"nasdaq_earning_calendar.csv\", )\n",
    "    \"\"\"\n",
    "    df_exdate_columns = df_exdate.columns\n",
    "    df_exdate[\"ExDate\"] = True \n",
    "    df_exdate[\"date_symbol\"] = df_exdate[\"Time\"] + \"_\" + df_exdate[\"Symbol\"]\n",
    "    df_exdate = df_exdate.set_index(\"date_symbol\")\n",
    "    \n",
    "    pipeline_results[\"date\"] = pipeline_results.index.get_level_values(0).format(formatter=lambda x: x.strftime('%Y-%m-%d'))\n",
    "    pipeline_results[\"symbol\"] = [s.symbol for s in pipeline_results.index.get_level_values(1)]\n",
    "    pipeline_results[\"date_symbol\"] = pipeline_results[\"date\"] + \"_\" + pipeline_results[\"symbol\"]\n",
    "    pipeline_results = pipeline_results.reset_index().set_index(\"date_symbol\")\n",
    "    \n",
    "    pipeline_results_1 = pipeline_results.merge(df_exdate, how=\"inner\", left_index=True, right_index=True)\n",
    "    \n",
    "    pipeline_results_1 = pipeline_results_1.reset_index().set_index([\"level_0\", \"level_1\"])\n",
    "    pipeline_results_1 = pipeline_results_1.drop(df_exdate_columns, axis=1)\n",
    "    return pipeline_results_1\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 当日の一分足データを作成\n",
    "\n",
    "#### get_prices の返り値\n",
    "\n",
    "```\n",
    "<class 'pandas.core.panel.Panel'>\n",
    "Dimensions: 7 (items) x 390 (major_axis) x 112 (minor_axis)\n",
    "Items axis: open_price to turnover\n",
    "Major_axis axis: 2017-05-15 13:31:00+00:00 to 2017-05-15 20:00:00+00:00\n",
    "Minor_axis axis: Equity(24 [AAPL]) to Equity(49242 [PYPL])\n",
    "```\n",
    "\n",
    "#### calc_gap の 返り値\n",
    "\n",
    "ID|book_value_yield|dividend_yield|gap|latest_turnover|market_cap|net_income_growth|normalized_basic_eps|pe|roa|roe|rsi|sector|turnover_ratio\n",
    "---|---|---|---|---|---|---|---|---|---|---|---|---|---\n",
    "Equity(24 [AAPL])|0.167|0.0152|-0.0041|7627489.44|27.411211|0.048783|2.11|17.9429|0.033136|0.082778|85.578218|311|0.00174\n",
    "Equity(62 [ABT])|0.4121|0.0239|0.005119|321991.575|25.055432|0.325949|0.22|49.2809|0.006783|0.016146|46.619217|206|0.001503\n",
    "\n",
    "\n",
    "#### get_minutewise の返り値\n",
    "\n",
    "⇑日付をキーに，get_pricesとcalc_gapを値として格納した辞書2つをタプルとして返す\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prices(pipeline_results, date):\n",
    "    \"\"\"\n",
    "    date当日の1分データを返す．\n",
    "    pipeline_results: build_pipelineの返り値\n",
    "    date: 日付データ．\n",
    "    \n",
    "    \"\"\"\n",
    "    # 各dateでpipelineでフィルターされた sids の一分足を取得する\n",
    "    sids = pipeline_results.ix[date].index\n",
    "    pan_today_1m = get_pricing(sids, start_date=date, end_date=date, frequency='minute')\n",
    "    pan_today_1m['turnover'] = pan_today_1m.price * pan_today_1m.volume\n",
    "    return pan_today_1m\n",
    "\n",
    "\n",
    "def calc_gap(df_pipeline_results_prevday, pan_today_1m, observe_timing=1):\n",
    "    \"\"\"\n",
    "    df_pipeline_results_prevday: pipeline_results.ix[date]で得られるDataFrame\n",
    "    pan_today_1m: get_pricesの返り値\n",
    "    observe_timing: [optional] マーケットオープン後，何分経ってからGapを観測するか指定する．デフォルトは1（分後，つまり09：31）\n",
    "    \n",
    "    Return: df_eligibles．Index は 銘柄id(sid) \n",
    "    \"\"\"\n",
    "    \n",
    "    s_latest_price = pan_today_1m['price', observe_timing, :] #pan_today_1m.price.ix[observe_timing]\n",
    "    s_latest_turnover = pan_today_1m['turnover', observe_timing, :] #pan_today_1m.turnover.ix[observe_timing]\n",
    "\n",
    "    s_turnover = df_pipeline_results_prevday.yesterday_turnover\n",
    "    s_prev_close = df_pipeline_results_prevday.yesterday_close\n",
    "\n",
    "    df_eligibles = pd.DataFrame({\n",
    "        'gap': s_latest_price / s_prev_close - 1.0,\n",
    "        'turnover_ratio': s_latest_turnover/s_turnover,\n",
    "        'rsi': df_pipeline_results_prevday.rsi,\n",
    "        'sector': df_pipeline_results_prevday.sector,\n",
    "        'latest_turnover':s_latest_turnover,\n",
    "            #\n",
    "        'market_cap': df_pipeline_results_prevday.market_cap,\n",
    "        'roa': df_pipeline_results_prevday.roa,\n",
    "        'roe': df_pipeline_results_prevday.roe,\n",
    "        'normalized_basic_eps': df_pipeline_results_prevday.normalized_basic_eps,\n",
    "        'net_income_growth': df_pipeline_results_prevday.net_income_growth,\n",
    "        'pe': df_pipeline_results_prevday.pe,\n",
    "        'book_value_yield': df_pipeline_results_prevday.book_value_yield,\n",
    "        'dividend_yield': df_pipeline_results_prevday.dividend_yield,\n",
    "        #'short_name': ShortName(),\n",
    "        #'period_ending_date': df_pipeline_results_prevday.PeriodEndingDate(),        \n",
    "    })\n",
    "    return df_eligibles\n",
    "\n",
    "\n",
    "def get_minutewise(pipeline_results):\n",
    "    \"\"\"\n",
    "    get_pricesとcalc_gapを使って，各日付の一分足データとその分足データを使って，インディケータDataFrameを作成\n",
    "    \n",
    "    \"\"\"\n",
    "    dict_daily = dict()\n",
    "    dict_pan_today_1m = dict()\n",
    "    \n",
    "    # pipeline_resultsから日付データを取り出し\n",
    "    dates = pipeline_results.index.get_level_values(0).unique()\n",
    "    observe_timing = 40\n",
    "    for date in dates:\n",
    "        print date.strftime(\"%Y-%m-%d\"),\n",
    "        df_pipeline_results_prevday = pipeline_results.ix[date]\n",
    "        pan_today_1m = get_prices(pipeline_results, date)\n",
    "        df_eligibles = calc_gap(df_pipeline_results_prevday, pan_today_1m, observe_timing,)\n",
    "        dict_daily[date] = df_eligibles\n",
    "        dict_pan_today_1m[date] = pan_today_1m\n",
    "    return dict_daily, dict_pan_today_1m\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAP UP 銘柄のみを探す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_gapups(dict_daily, \n",
    "               gapup_min_turnover_ratio,\n",
    "               gapup_max_turnover_ratio,\n",
    "               gapup_min_gap,\n",
    "               gapup_max_gap):\n",
    "    \"\"\"\n",
    "    get_minutewiseの返り値，dict_dailyから，gapup銘柄のみをフィルターにかけて返す．\n",
    "    \n",
    "    Return: 各日付がキー，gapup銘柄のみのDataFrameを値に持つ辞書\n",
    "    \"\"\"\n",
    "    \n",
    "    dict_daily_gapups = dict()\n",
    "    dates = dict_daily.keys()\n",
    "    for date in dates:\n",
    "        df_eligibles = dict_daily[date]\n",
    "        df_gapups =  df_eligibles[(df_eligibles.turnover_ratio > gapup_min_turnover_ratio)\n",
    "                                  & (df_eligibles.turnover_ratio < gapup_max_turnover_ratio)\n",
    "                                  & (df_eligibles.gap > gapup_min_gap )\n",
    "                                  & (df_eligibles.gap < gapup_max_gap )\n",
    "                                 ].sort_values(by=['gap'], ascending=[False])\n",
    "        dict_daily_gapups[date] = df_gapups\n",
    "    return dict_daily_gapups\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### その他\n",
    "\n",
    "* spy の分足データを取得\n",
    "* exdates の追加\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spy(pipeline_results):\n",
    "    dates = pipeline_results.index.get_level_values(0).unique()\n",
    "    spy = get_pricing(symbols('spy'), start_date=dates[0], end_date=dates[-1], frequency='daily')\n",
    "    spy['gap'] =  spy.open_price / spy.close_price.shift(1) - 1\n",
    "    return spy\n",
    "\n",
    "def add_exdate(dict_daily_gaps, date, df_earning_calendar):\n",
    "    df_daily_gaps = dict_daily_gaps[date]\n",
    "    today_is_exdate = df_earning_calendar.ix[date][\"Symbol\"]\n",
    "    smbls =  [s.symbol for s in df_daily_gaps.index]\n",
    "    \n",
    "    if type(today_is_exdate) == str:\n",
    "        today_is_exdate = [today_is_exdate]\n",
    "        \n",
    "    if type(today_is_exdate) == pd.Series and today_is_exdate.empty:\n",
    "        df_daily_gaps[\"ExDate\"] = pd.Series()\n",
    "        return df_daily_gaps\n",
    "        \n",
    "    df_daily_gaps[\"ExDate\"] = pd.Series([s in  today_is_exdate for s in smbls])\n",
    "    return df_daily_gaps\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_performance_data(dict_daily_gaps, dict_pan_today_1m):\n",
    "    \"\"\"\n",
    "    dict_daily_gapups：get_daily_gapups / get_daily_gapups の返り値(get_daily_gapupsはまだ作ってません）\n",
    "    dict_pan_today_1m：get_minutewiseの返り値dict_pan_today_1m\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    #special_dates = dates#[(\"2014-1-1\" < dates) & (dates < \"2015-1-1\") & (6 < dates.month) & ( dates.month <= 12)]\n",
    "    dates = dict_daily_gaps.keys()\n",
    "    l = list()\n",
    "    for date in dates:\n",
    "        r = dict_daily_gaps[date]\n",
    "        #r = add_exdate(dict_daily_gaps, date, df_earning_calendar)\n",
    "        \n",
    "        df = dict_pan_today_1m[date]['price', :, r.index]\n",
    "        if not df.empty:\n",
    "            df = df.reset_index(drop=True)\n",
    "            #df = df.pct_change().cumsum()\n",
    "            df = (df.pct_change()+1.0).apply(np.log).cumsum()\n",
    "            m5 = df.ix[5]\n",
    "            m10 = df.ix[10]\n",
    "            l.append(pd.DataFrame({\n",
    "                'date':date,\n",
    "                'sector': r.sector,\n",
    "                'gap': r.gap,\n",
    "                'spy_gap': spy['gap'].ix[date],\n",
    "                'spy_gap_diff': r.gap-spy['gap'].ix[date],\n",
    "                'latest_turnover': r.latest_turnover.apply(np.log),\n",
    "                'turnover_ratio': r.turnover_ratio,\n",
    "                'market_cap': r.market_cap,\n",
    "                'roa': r.roa,\n",
    "                'roe': r.roe,\n",
    "                'normalized_basic_eps': r.normalized_basic_eps,\n",
    "                'net_income_growth': r.net_income_growth,\n",
    "                'pe': r.pe,\n",
    "                'book_value_yield': r.book_value_yield,\n",
    "                'dividend_yield': r.dividend_yield,   \n",
    "                'exdate': r.ExDate,\n",
    "                #\n",
    "                '05m': m5,\n",
    "                '10m': m10,\n",
    "                '15m': df.ix[15],\n",
    "                '20m': df.ix[20],\n",
    "                '25m': df.ix[25],\n",
    "                '30m': df.ix[30],\n",
    "                '35m': df.ix[35],\n",
    "                '40m': df.ix[40],\n",
    "                '45m': df.ix[45],\n",
    "                '50m': df.ix[50],\n",
    "                #\n",
    "                #'10m_5m': df.ix[10]-m5,\n",
    "                '15m_5m': df.ix[15]-m5,\n",
    "                '20m_5m': df.ix[20]-m5,\n",
    "                '25m_5m': df.ix[25]-m5,\n",
    "                '30m_5m': df.ix[30]-m5,\n",
    "                '35m_5m': df.ix[35]-m5,\n",
    "                '40m_5m': df.ix[40]-m5,\n",
    "                '45m_5m': df.ix[45]-m5,\n",
    "                '50m_5m': df.ix[50]-m5,\n",
    "                #\n",
    "                #'15m_10m': df.ix[15]-m10,\n",
    "                '20m_10m': df.ix[20]-m10,\n",
    "                '25m_10m': df.ix[25]-m10,\n",
    "                '30m_10m': df.ix[30]-m10,\n",
    "                '35m_10m': df.ix[35]-m10,\n",
    "                '40m_10m': df.ix[40]-m10,\n",
    "                '45m_10m': df.ix[45]-m10,\n",
    "                '50m_10m': df.ix[50]-m10,\n",
    "              }))\n",
    "\n",
    "            return pd.concat(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date, end_date='2017-1-1', '2017-1-10'\n",
    "#start_date, end_date='2016-1-1', '2017-6-1'\n",
    "#start_date, end_date='2015-1-1', '2016-1-1'\n",
    "#start_date, end_date='2014-1-1', '2015-1-1'\n",
    "high_dollar_volume_thresh_min = 90  # 98\n",
    "high_dollar_volume_thresh_max = 95  # 100\n",
    "pipeline_results = build_pipeline(start_date, end_date, high_dollar_volume_thresh_min, high_dollar_volume_thresh_max)\n",
    "\n",
    "df_exdate = local_csv(\"nasdaq_earning_calendar.csv\", )\n",
    "pipeline_results = add_exdates(pipeline_results, df_exdate)\n",
    "\n",
    "dict_daily, pan_today_minutewise = get_minutewise(pipeline_results)\n",
    "\n",
    "gapup_min_turnover_ratio = 0.0\n",
    "gapup_max_turnover_ratio = 1.0\n",
    "gapup_min_gap = -1.0\n",
    "gapup_max_gap = 1.0\n",
    "#\n",
    "dict_daily_gapups = get_daily_gapups(dict_daily, \n",
    "               gapup_min_turnover_ratio,\n",
    "               gapup_max_turnover_ratio,\n",
    "               gapup_min_gap,\n",
    "               gapup_max_gap)\n",
    "\n",
    "spy = get_spy(pipeline_results)\n",
    "df = get_performance_data(dict_daily_gapups, pan_today_minutewise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_cal = df_earning_calendar.ix[\"2017-10-1\"][\"Symbol\"]\n",
    "s_cal\n",
    "#s_index = [s.symbol for s in dict_daily_gapups[dates[0]].index]\n",
    "\n",
    "#pd.Series([s in  [s_cal] for s in s_index], name=\"ExDate\")\n",
    "\n",
    "add_exdate(dict_daily_gapups, dates[1], df_earning_calendar)\n",
    "df_earning_calendar.ix[dates[1]][\"Symbol\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_daily_gapups[dates[1]][\"Symbol\"] = [s.symbol for s in dict_daily_gapups[dates[1]].index]\n",
    "dict_daily_gapups[dates[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor \n",
    "\n",
    "def build_model(df, features, target, train_ratio, show_chart):\n",
    "    df_all = df[features+[target]].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    df_features = df_all[features]\n",
    "    df_return = df_all[target]\n",
    "    np_features = df_features.as_matrix()\n",
    "    np_return = df_return.as_matrix().ravel()\n",
    "    #\n",
    "    num_train = int(len(df_all.index)*train_ratio)\n",
    "    np_features_train = np_features[:num_train,:]\n",
    "    np_return_train = np_return[:num_train]\n",
    "    np_features_test = np_features[num_train:,:]\n",
    "    np_return_test = np_return[num_train:]\n",
    "    #\n",
    "    rfr = RandomForestRegressor(100)\n",
    "    rfr.fit(np_features_train, np_return_train)     \n",
    "    pred_train = rfr.predict(np_features_train) \n",
    "    pred_test = rfr.predict(np_features_test) \n",
    "    #\n",
    "    if show_chart:\n",
    "        fig = plt.figure(figsize = (16,8))\n",
    "        ax = fig.add_subplot(1,2,1)\n",
    "        ax.scatter(pred_train, np_return_train, color='b', alpha=0.2)   \n",
    "        bx = fig.add_subplot(1,2,2)\n",
    "        bx.scatter(pred_test, np_return_test, color='r', alpha=0.2)  \n",
    "        xlim = min(pred_train.min(), pred_test.min()), max(pred_train.max(), pred_test.max())\n",
    "        ylim = min(np_return_train.min(), np_return_test.min()), max(np_return_train.max(), np_return_test.max())\n",
    "        ax.set_xlim(xlim)\n",
    "        ax.set_ylim(ylim)\n",
    "        bx.set_xlim(xlim)\n",
    "        bx.set_ylim(ylim)\n",
    "        print(num_train)\n",
    "        print(len(df_features.index)-num_train)\n",
    "\n",
    "features = [u'book_value_yield', u'dividend_yield', u'gap',\n",
    "       u'latest_turnover', u'market_cap', u'net_income_growth',\n",
    "       u'normalized_basic_eps', u'pe', u'roa', u'roe', u'spy_gap',\n",
    "       u'spy_gap_diff', u'turnover_ratio',\n",
    "       #u'05m' \n",
    "           ] # u'date', u'sector', \n",
    "\n",
    "target = u'45m_10m'\n",
    "df_data = df[abs(df.spy_gap_diff) > 0.0025]\n",
    "#df_data = df[df.spy_gap_diff < -0.01]\n",
    "train_ratio = 0.8\n",
    "show_chart = True\n",
    "model = build_model(df_data, features, target, train_ratio, show_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.scatter(x['gap'],x['5m'], s=2, color='blue')\n",
    "thresh = 0.005\n",
    "#margin = 0.01\n",
    "x = x[(x.spy_gap < -thresh) | (x.spy_gap > thresh) ]\n",
    "x = x[(x.sector != 102) & (x.sector != 105) & (x.sector != 301)]\n",
    "#x = x[(x.gap < x.spy-margin) | (x.gap > x.spy+margin) ]\n",
    "fig = plt.figure()\n",
    "#plt.xlim([-0.02, 0.0])\n",
    "#plt.ylim([-0.05, 0.05])\n",
    "\n",
    "Y = target\n",
    "sx = x['spy_gap_diff']\n",
    "sy = x[Y]\n",
    "\n",
    "sz = x['turnover_ratio'].apply(np.log)\n",
    "sz = x['pe'].apply(np.log)\n",
    "#sz = x['latest_turnover']\n",
    "#sz = x['sector']\n",
    "\n",
    "plt.xlabel('gap-sp/gap')\n",
    "plt.ylabel(Y)\n",
    "\n",
    "im = plt.scatter(sx,\n",
    "                 sy,\n",
    "                 #s=5,\n",
    "                 c=sz , ## 配色を決定する三番目のデータ\n",
    "                 linewidths=0, alpha=1,\n",
    "                 cmap=cm.coolwarm, # ここでカラーマップを指定\n",
    "                 #vmin=0.94,\n",
    "                 #vmax=0.003,\n",
    "                )\n",
    "fig.colorbar(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
