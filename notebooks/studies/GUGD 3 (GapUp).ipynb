{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 2017/07/27　Updated\n",
    "+ pipeline は，アジャストされていないの，フィルタリングにだけ使うようにUpdate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantopian.pipeline.data.builtin import USEquityPricing\n",
    "from quantopian.pipeline.factors import SimpleMovingAverage\n",
    "from quantopian.research import run_pipeline\n",
    "from quantopian.pipeline import Pipeline,CustomFilter\n",
    "from quantopian.pipeline.factors import CustomFactor,RSI\n",
    "from quantopian.pipeline.data import morningstar\n",
    "from zipline import TradingAlgorithm  \n",
    "from quantopian.pipeline.filters import Q1500US, Q500US\n",
    "from quantopian.pipeline.factors import AverageDollarVolume\n",
    "import numpy as np\n",
    "import talib \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from quantopian.pipeline.filters.morningstar import IsPrimaryShare\n",
    "from quantopian.pipeline.classifiers.morningstar import Sector, SuperSector\n",
    "\n",
    "\n",
    "# class PrevClose(CustomFactor):\n",
    "#     inputs = [USEquityPricing.close]\n",
    "#     window_length = 2\n",
    "#     def compute(self, today, assets, out, close):\n",
    "#         out[:] = close[-2]\n",
    "        \n",
    "# class PrevVolume(CustomFactor):\n",
    "#     inputs = [USEquityPricing.volume]\n",
    "#     window_length = 2\n",
    "#     def compute(self, today, assets, out, close):\n",
    "#         out[:] = close[-2]\n",
    "        \n",
    "def make_pipeline():\n",
    "    base_universe = Q500US() if False else Q1500US()\n",
    "#     yesterday_close = PrevClose()\n",
    "#     yesterday_volume = PrevVolume()\n",
    "    dollar_volume = AverageDollarVolume(window_length=30)\n",
    "    #ToDo この範囲を色々変えてみる．\n",
    "\n",
    "    primary_share = IsPrimaryShare()\n",
    "    # Equities listed as common stock (as opposed to, say, preferred stock).\n",
    "    # 'ST00000001' indicates common stock.\n",
    "    common_stock = morningstar.share_class_reference.security_type.latest.eq('ST00000001')\n",
    "    # Non-depositary receipts. Recall that the ~ operator inverts filters,\n",
    "    # turning Trues into Falses and vice versa\n",
    "    not_depositary = ~morningstar.share_class_reference.is_depositary_receipt.latest\n",
    "    # Equities not trading over-the-counter.\n",
    "    not_otc = ~morningstar.share_class_reference.exchange_id.latest.startswith('OTC')\n",
    "    # Not when-issued equities.\n",
    "    not_wi = ~morningstar.share_class_reference.symbol.latest.endswith('.WI')\n",
    "    # Equities without LP in their name, .matches does a match using a regular expression\n",
    "    not_lp_name = ~morningstar.company_reference.standard_name.latest.matches('.* L[. ]?P.?$')\n",
    "    # Equities with a null value in the limited_partnership Morningstar fundamental field.\n",
    "    not_lp_balance_sheet = morningstar.balance_sheet.limited_partnership.latest.isnull()\n",
    "    # Equities whose most recent Morningstar market cap is not null have fundamental data and therefore are not ETFs.\n",
    "    have_market_cap = morningstar.valuation.market_cap.latest.notnull()\n",
    "    \n",
    "    is_cyclical = SuperSector().eq(SuperSector.CYCLICAL)\n",
    "    is_defensive = SuperSector().eq(SuperSector.DEFENSIVE)\n",
    "    is_sensitive = SuperSector().eq(SuperSector.SENSITIVE)    \n",
    "    high_dollar_volume = dollar_volume.percentile_between(98, 100)\n",
    "    \n",
    "    tradeable_stocks = (\n",
    "        primary_share\n",
    "        &common_stock\n",
    "        &not_depositary\n",
    "        &not_otc\n",
    "        &not_wi\n",
    "        &not_lp_name\n",
    "        &not_lp_balance_sheet\n",
    "        &have_market_cap\n",
    "        &(is_cyclical | is_defensive | is_sensitive))   \n",
    "\n",
    "    pipe = Pipeline(\n",
    "        columns = {\n",
    "            'dollar_volume': dollar_volume,\n",
    "            'high_dollar_volume': high_dollar_volume, \n",
    "        },\n",
    "        screen = base_universe & high_dollar_volume #& rsi_under_60\n",
    "    )\n",
    "    return pipe\n",
    "\n",
    "def my_get_pricing(results, start, end=None):\n",
    "\n",
    "    if not end:\n",
    "        end = start\n",
    "    # 銘柄はendの日付で取得する．        \n",
    "    sids = results.ix[end].index\n",
    "    pan = get_pricing(sids, start_date=start, end_date=end, frequency='minute') \n",
    "    pan['turnover'] = pan.price * pan.volume\n",
    "    return pan \n",
    "\n",
    "def find_gapup(results, pan, date, turnover_threshold=0.05, gapup_threshold = 0.0):\n",
    "    #print pan\n",
    "\n",
    "    df = pd.DataFrame({'gap': (pan.price.ix[0] / results.ix[date].yesterday_close - 1),\n",
    "                       'turnover': (pan.turnover.ix[0] / results.ix[date].yesterday_turnover)})\n",
    "    df = df.sort_values(by=['gap','turnover'], ascending=[True,True])\n",
    "    df_gapups = df[(df.turnover > turnover_threshold) & (df.gap > gapup_threshold)]\n",
    "    return df_gapups\n",
    "\n",
    "def get_gapup_data(pan, df_gapups):\n",
    "    # ⇓⇓⇓⇓\n",
    "    top_gapup_sids = df_gapups.tail(5).index \n",
    "#     if top_gapup_sids.any(): print top_gapup_sids\n",
    "    pan_sids = pan[:,:,top_gapup_sids]\n",
    "    df_gapup_sids_data_for_an_hour = (pan_sids.price.ix[0] / pan_sids.price -1).ix[:60].reset_index(drop=True)\n",
    "    return df_gapup_sids_data_for_an_hour\n",
    "\n",
    "def get_gapup_data2(pan, df_gapups):\n",
    "\n",
    "    top_gapup_sids = df_gapups.index \n",
    "    pan = pan[:,:,top_gapup_sids]\n",
    "    \n",
    "    prevdate = pan.price.ix[:390]\n",
    "    today = pan.price.ix[390:]\n",
    "\n",
    "    dscrb = prevdate.fillna(method='ffill').fillna(method='backfill').pct_change().dropna().describe()\n",
    "    top_gapup_sids = dscrb.loc[:, dscrb.loc['mean'] > 0].T.index\n",
    "    \n",
    "    if top_gapup_sids.any():\n",
    "        print sorted([s.symbol for s in top_gapup_sids]), \n",
    "        pan_sids = today[top_gapup_sids]\n",
    "        # short \n",
    "        df_gapup_sids_data_for_an_hour = (pan_sids.ix[0] / pan_sids -1).ix[:60].reset_index(drop=True)\n",
    "        return df_gapup_sids_data_for_an_hour\n",
    "    else:\n",
    "        return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_pipeline(make_pipeline(), start_date='2017-6-1', end_date='2017-7-20')\n",
    "dates = results.index.get_level_values(0).unique()\n",
    "\n",
    "print dates\n",
    "l = list()\n",
    "m = 0\n",
    "for i, date in enumerate(dates):\n",
    "    if date.strftime(\"%m\") != m:\n",
    "        print date \n",
    "        m = date.strftime(\"%m\")\n",
    "    if i > 1:\n",
    "        sids = results.ix[date].index\n",
    "        target_date = get_pricing(sids, start_date = date, end_date = date, fields = [\"price\", \"volume\", \"close_price\", \"open_price\"])\n",
    "        day_before_yesterday = get_pricing(sids, start_date = dates[i-2], end_date = dates[i-2],fields = [\"close_price\", \"volume\", \"price\"])\n",
    "        \n",
    "        target_date['turnover'] = target_date[\"price\"] * target_date[\"volume\"]\n",
    "        day_before_yesterday['turnover'] = day_before_yesterday[\"close_price\"] * day_before_yesterday[\"volume\"]\n",
    "        \n",
    "        target_date_minute_data = get_pricing(sids, start_date = date, end_date = date, fields = \"price\", frequency='minute')\n",
    "        target_date_minute_data.index = target_date_minute_data.index.tz_convert(\"US/Eastern\")\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            'gap': target_date['price'].iloc[0] / day_before_yesterday['close_price'].iloc[0] -1, \n",
    "            'gap2': target_date['price'].iloc[0] / day_before_yesterday['price'].iloc[0] -1, \n",
    "            'gap3': target_date['open_price'].iloc[0] / day_before_yesterday['price'].iloc[0] -1,             \n",
    "            'turnover_ratio': target_date['turnover'].iloc[0] / day_before_yesterday['turnover'].iloc[0],\n",
    "            # UTC\n",
    "            'return_between_0930_1010': \n",
    "            target_date_minute_data.at_time(\"10:10\").iloc[0]/ target_date_minute_data.at_time(\"09:31\").iloc[0]- 1,\n",
    "            'today':date,\n",
    "            'day_before_yesterday': dates[i-2],\n",
    "            'close_day_before_yesterday': day_before_yesterday[\"close_price\"].iloc[0],\n",
    "            'entry_price':  target_date_minute_data.at_time(\"09:31\").iloc[0],\n",
    "            'exit_price': target_date_minute_data.at_time(\"10:10\").iloc[0],\n",
    "            \n",
    "        })\n",
    "        \n",
    "        l.append(df)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.concat(l)\n",
    "# x = x[\n",
    "#     (x['gap'] > 0.10) \n",
    "#       & (x['gap'] < 1.0)\n",
    "#       & (x['turnover_ratio'] > 0)\n",
    "#       & (x['turnover_ratio'] < 0.6)\n",
    "#       ]\n",
    "fig = plt.figure()\n",
    "im = plt.scatter(x.gap, \n",
    "                 x.return_between_0930_1010, \n",
    "                 c=x.turnover_ratio, ## 配色を決定する三番目のデータ\n",
    "                 linewidths=0, alpha=1, \n",
    "                 cmap=cm.hot # ここでカラーマップを指定\n",
    "                 )\n",
    "fig.colorbar(im)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[(x.today == \"2017-07-06\")].ix[symbols(\"AMD\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amd = get_pricing(symbols(\"AMD\"), start_date='2017-6-1', end_date='2017-7-20', frequency='minute', fields='price')\n",
    "amd.index = amd.index.tz_convert(\"US/Eastern\")\n",
    "def at_two_times(df, time1, time2, time3):\n",
    "    idx = np.sort(np.concatenate((df.index.indexer_at_time(time1) , \n",
    "                                  df.index.indexer_at_time(time2), \n",
    "                                  df.index.indexer_at_time(time3))))\n",
    "    return df.ix[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_two_times(amd, \"09:31\", \"10:11\", \"16:00\").ix[\"2017-6-15\":]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results = run_pipeline(make_pipeline(), start_date='2016-1-1', end_date='2017-1-10')\n",
    "\n",
    "dates = results.index.get_level_values(0).unique()\n",
    "\n",
    "l = list()\n",
    "for i, date in enumerate(dates):\n",
    "    if i > 0: \n",
    "        print date.strftime(\"%Y-%m-%d\"),\n",
    "        df = results.ix[date]\n",
    "        pan = my_get_pricing(results, dates[i-1], date)\n",
    "        prevday = pan[:,:390,:]\n",
    "        today   = pan[:,390:,:]\n",
    "        prev_dscr=prevday.price.fillna(method='ffill').fillna(method='backfill').pct_change().dropna().describe().T\n",
    "        prev_dscr = prev_dscr.rename(columns=dict([(c, \"yesterday_\"+c) for c in prev_dscr.columns]))\n",
    "        today_dscr = today.price.ix[:60].fillna(method='ffill').fillna(method='backfill').pct_change().dropna().describe().T\n",
    "        today_dscr = today_dscr.rename(columns=dict([(c, \"today_\"+c) for c in today_dscr.columns]))\n",
    "        gap = pd.DataFrame({\"gap\":today.price.ix[0] / prevday.price.ix[-1] -1})\n",
    "        turnover = pd.DataFrame({\"turnover_impact\":today.turnover.ix[0] / df.yesterday_turnover })\n",
    "        df_concat = pd.concat([df, prev_dscr, today_dscr,gap,turnover], axis=1)        \n",
    "        l.append(df_concat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[c for c in l[0].columns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(l)\n",
    "import matplotlib.cm as cm\n",
    "fig = plt.figure()\n",
    "\n",
    "x = df[(df.yesterday_turnover > df.yesterday_turnover.dropna().quantile(0.98) )\n",
    "#        & (df.yesterday_mean > 0.001)\n",
    "      ]\n",
    "#x.plot.scatter(x = \"gap\", y = \"today_mean\", ylim=[-0.003, 0.003])#xlim= [0,0.0025], ylim=[-0.002, 0.002]\n",
    "\n",
    "im = plt.scatter(x.gap, \n",
    " x['today_mean'],\n",
    " c=x['yesterday_std'], ## 配色を決定する三番目のデータ\n",
    " linewidths=0, alpha=1, \n",
    " cmap=cm.seismic,\n",
    " \n",
    " )\n",
    "# plt.ylim(-0.002, 0.003)\n",
    "fig.colorbar(im)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_pipeline(make_pipeline(), start_date='2015-1-1', end_date='2016-1-10')\n",
    "dates = results.index.get_level_values(0).unique()\n",
    "turnover_thresholds = [0]#range(0,6)\n",
    "gapup_thresholds = [0]#range(0,6)\n",
    "xys = [(t,g) for t in turnover_thresholds for g in gapup_thresholds]\n",
    "\n",
    "l = list()\n",
    "d = dict()\n",
    "for i, date in enumerate(dates): \n",
    "    if i > 0:\n",
    "        print date.strftime(\"%Y-%m-%d\"),\n",
    "        pan = my_get_pricing(results, dates[i-1], date)\n",
    "        for t, g in xys:\n",
    "            df_gapups = find_gapup(results, pan[:,:390,:], date, t/100.0, g/100.0)\n",
    "            df_gapup_sids_data_for_an_hour = get_gapup_data2(pan, df_gapups)\n",
    "            if df_gapup_sids_data_for_an_hour is not None:\n",
    "                if not df_gapup_sids_data_for_an_hour.empty :\n",
    "                    k = \"%s_%s\" % (t/100.0, g/100.0)\n",
    "                    print len(df_gapup_sids_data_for_an_hour.columns)\n",
    "                    if k not in d.keys():\n",
    "                        d[k] = df_gapup_sids_data_for_an_hour\n",
    "                    else:\n",
    "                        d[k] = pd.concat([d[k],df_gapup_sids_data_for_an_hour], axis=1)\n",
    "                #l.append((\"%s_%s\" % (t/100.0, g/-100.0), df_gapup_sids_data_for_an_hour))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([prev_dscr, df.T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_pipeline(make_pipeline(), start_date='2015-1-1', end_date='2016-1-7')\n",
    "dates = results.index.get_level_values(0).unique()\n",
    "turnover_thresholds = [0] #range(0,6)\n",
    "gapup_thresholds = [0] #range(0,6)\n",
    "xys = [(t,g) for t in turnover_thresholds for g in gapup_thresholds]\n",
    "\n",
    "l = list()\n",
    "d = dict()\n",
    "for date in dates: \n",
    "    print date.strftime(\"%Y-%m-%d\"),\n",
    "    pan = my_get_pricing(results, date)\n",
    "    for t, g in xys:\n",
    "        df_gapups = find_gapup(results, pan, date, t/100.0, g/100.0)\n",
    "        df_gapup_sids_data_for_an_hour = get_gapup_data(pan, df_gapups)\n",
    "        if not df_gapup_sids_data_for_an_hour.empty:\n",
    "            k = \"%s_%s\" % (t/100.0, g/100.0)\n",
    "            if k not in d.keys():\n",
    "                d[k] = df_gapup_sids_data_for_an_hour\n",
    "            else:\n",
    "                d[k] = pd.concat([d[k],df_gapup_sids_data_for_an_hour], axis=1)\n",
    "        #l.append((\"%s_%s\" % (t/100.0, g/-100.0), df_gapup_sids_data_for_an_hour))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['0.0_0.0'].T.describe().ix['25%'].plot()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dscrb = prevdate.fillna(method='ffill').fillna(method='backfill').pct_change().dropna().describe()\n",
    "dscrb.loc[:, dscrb.loc['mean'] > 0].T.index\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
